{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAY1:从零实现BPE和Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码结构查看\n",
    "\n",
    "1. 下载`https://github.com/stanford-cs336/assignment1-basics`代码\n",
    "2. 阅读`readme.md`安装数据集、环境 \n",
    "\n",
    "``` python \n",
    "assignment1-basics/\n",
    "├── cs336_basics/          # 你的代码放在这里（初始为空）\n",
    "│   ├── __init__.py        # Python包初始化文件\n",
    "│   ├── bpe.py             # BPE分词器实现（需你编写）\n",
    "│   ├── transformer.py     # Transformer模型实现（需你编写）\n",
    "│   ├── optimizer.py       # AdamW优化器实现（需你编写）\n",
    "│   └── ...                # 其他必要文件\n",
    "├── adapters.py            # 测试适配器（不要修改，只需实现指定函数）\n",
    "├── test_*.py             # 测试文件（不要修改）\n",
    "├── data/                  # 数据集存放位置（需自行下载）\n",
    "└── README.md              # 作业说明\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE 分词器实现\n",
    "\n",
    "BPE（Byte Pair Encoding，字节对编码）是一种常用的子词分词算法，广泛应用于自然语言处理任务中，尤其是在大规模预训练模型（如GPT、BERT等）中。BPE的核心思想是通过统计训练语料中出现频率最高的相邻字符对，并将其合并为新的符号，逐步构建出一个高效的子词词表。这样可以有效减少词表大小，同时兼顾词汇覆盖率和表示能力。\n",
    "\n",
    "BPE的主要流程如下：\n",
    "1. 将文本按字符切分，初始时每个字符为一个token。\n",
    "2. 统计所有相邻token对的出现频率，找到出现频率最高的token对。\n",
    "3. 将该token对合并为一个新的token，更新语料。\n",
    "4. 重复步骤2-3，直到达到预设的词表大小或没有高频token对可合并。\n",
    "\n",
    "BPE的优点在于能够处理未登录词（OOV），并且在词表规模和分词粒度之间取得平衡。它既能保留常见词的整体性，又能将罕见词拆分为更小的子词单元，从而提升模型的泛化能力。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
